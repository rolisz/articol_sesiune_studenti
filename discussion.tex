\section{Discussion and Comparison to Related Work}
\label{sec:disc}

This section analyzes our approaches and compares them to similar existing work.

\subsection{Analysis of the Proposed Approach}
As shown in section \ref{sec:recog}, using an SVM with a RBF kernel seems to lead to slightly better results. One explanation for this would be that the data is already high dimensional (400 dimensions) and the data points lie in sufficiently different parts so that the separating hyperplanes work effectively, without needing a projection into the infinite dimensional space offered by the RBF kernel. 

In the case of the character segmentation, the values of the parameter didn't matter that much. The difference between the best and the worst result was about 0.2. The number of features had the most influence, of $ 0.1\% $, on the F1 score, while the number of trees influenced it only by 0.01. The highest average was obtained for the values of 250 trees in the forest and 40 features chosen at each split, giving an F1 score of $ 87.936\% \pm 0.445$ on the validation set and a score of $ 91.99\% $ on the test set.  

This seems to indicate that the number of features that are chosen at each split point is a more important parameter for random forests, while the number of trees used in the forest doesn't vary the results so much. This is in line with the theoretical basis of random forests\cite{breiman2001random}, which suggest that random forests are somewhat sensitive to the number of features used in them. 

If we look at the confusion matrix for the character recognition problem, computed for the whole data set, we can see that one of the most often made mistakes are:
\begin{itemize}
\item confusing , with . - 28 times
\item confusing . with , - 12 times
\item confusing O with 0 - 24 times
\item confusing 0 with O - 15 times
\item confusing 0 with o - 3 times
\item confusing l with I - 6 times
\item confusing I with T - 5 times
\item confusing I with 1 - 4 times
\item confusing 1 with I - 4 times
\end{itemize} 

These mistakes are easy to make: a comma and a period are very similar, especially in a noisy, low resolution environment. The lower and upper case letters O are again very similar to the digit 0, on some receipts there being no distinction between O and 0, only the context in which they are used. For monospace fonts, which some receipts use, the lack of difference between l, I, 1 is a well known problem, which is why many design books and human computer interaction studies recommend using other fonts\cite{chaparro2006examining}. 

If we look at the confusion matrix for the character segmentation problem, we see that it makes the mistake of not predicting a split more often than it does the opposite, so the model is more specific, rather then sensitive. 

Specifity and sensitivity can be computed as\cite{Fawcett_2006}

\[
    \text{sensitivity} = \frac{\text{true positives}}{\text{all positives}} = \frac{2546}{2546+363} = 87.52 \%
\]
\[
    \text{specificity} = \frac{\text{true negatives}}{\text{all negatives}} = \frac{4556}{4556+255} =  94.70 \%
\]

Another good evaluation measure is the \textit{Area unde the ROC curve} (AUC)\cite{Fawcett_2006}. The \textit{ROC} (Receiver Operating Characteristic) curve is a plot of \textit{sensitivity} versus (1 - \textit{specificity}). Usually they are constructed from classifiers that instead of a label, return a score that can be converted into a label by thresholding. In the case of classifiers that return the class directly, the ROC curve has only one point, from where the AUC measure can be computed. 

In our case, the AUC is 0.911, as computed from the graph in figure \ref{fig:roc}. 
